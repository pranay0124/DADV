{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import csv\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for files in glob.glob('E:\\\\DADV\\\\Exam\\\\500_day\\\\*.csv'):\n",
    "    f=open(files, 'r')\n",
    "    name = os.path.basename(f.name).replace(\".csv\",\"\")\n",
    "    data = pd.read_csv(f)\n",
    "    close = data[\"gainORloss\"]\n",
    "    val = close[len(close) - 1] - close[1]\n",
    "    dic[name] = val\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sorting a dictionary\n",
    "sorteddic = {k: v for k, v in sorted(dic.items(), key=lambda item: item[1], reverse = True)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 1\n",
    "topdict = {}\n",
    "for each in sorteddic.keys():\n",
    "    topdict[each] = sorteddic.get(each)\n",
    "    k = k+1\n",
    "    if(k == 26):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'GOOG': 2.8816842782153893,\n",
       " 'GOOGL': 2.6828123193805102,\n",
       " 'AIG': 1.686631042966269,\n",
       " 'AEP': 1.5195863719532738,\n",
       " 'AWK': 1.2987545833353997,\n",
       " 'LNT': 1.161512254102794,\n",
       " 'ATO': 1.113212486680875,\n",
       " 'AAP': 0.6846265877305393,\n",
       " 'AEE': 0.4375835822626801,\n",
       " 'MCD': 0.04596316506580414,\n",
       " 'AGN': -0.34608770583897863,\n",
       " 'MMM': -0.3574775081183144,\n",
       " 'AMD': -0.3624532458445495,\n",
       " 'AON': -0.5414259690189281,\n",
       " 'AFL': -0.9421683172502762,\n",
       " 'ALGN': -1.037033566220229,\n",
       " 'AJG': -1.055104790610239,\n",
       " 'ANTM': -1.1212174580230339,\n",
       " 'ALK': -1.1529862074690278,\n",
       " 'AIV': -1.1927639197676565,\n",
       " 'ALL': -1.2031702162270723,\n",
       " 'ARE': -1.306746216944561,\n",
       " 'ADM': -1.5222913973084995,\n",
       " 'AME': -1.569571472181264,\n",
       " 'AXP': -1.5815399707577045}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorteddicrev = {k: v for k, v in sorted(dic.items(), key=lambda item: item[1])}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 1\n",
    "bottomdict = {}\n",
    "for each in sorteddicrev.keys():\n",
    "    bottomdict[each] = sorteddicrev.get(each)\n",
    "    k = k+1\n",
    "    if(k == 26):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ALB': -10.506667108994685,\n",
       " 'AAL': -6.100111740590856,\n",
       " 'APTV': -5.2119024156695,\n",
       " 'AMP': -4.534361925402381,\n",
       " 'APH': -4.241878284207375,\n",
       " 'AMAT': -3.8184426520446744,\n",
       " 'ALXN': -3.6348120786067044,\n",
       " 'ABBV': -3.4832607785707133,\n",
       " 'ABMD': -3.318998964908082,\n",
       " 'ANSS': -3.2701972612962185,\n",
       " 'ABT': -2.785271199933419,\n",
       " 'AAPL': -2.7476619148632104,\n",
       " 'APD': -2.6174370883376126,\n",
       " 'AMZN': -2.3587579717335343,\n",
       " 'APA': -2.3352546139909087,\n",
       " 'AES': -2.3274532906090193,\n",
       " 'ADBE': -2.280435661778067,\n",
       " 'AIZ': -2.123551205636214,\n",
       " 'ATVI': -2.119400790878531,\n",
       " 'AMT': -2.072803239187835,\n",
       " 'ABC': -1.9028677052700802,\n",
       " 'ALLE': -1.674716005470473,\n",
       " 'AOS': -1.635407287514109,\n",
       " 'ARNC': -1.6352217573358587,\n",
       " 'AKAM': -1.6173083215993551}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bottomdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from scipy import interpolate\n",
    "corrlis = []\n",
    "for each1 in topdict.keys():\n",
    "    for each2 in topdict.keys():\n",
    "        corr_value = np.corrcoef(topdict.get(each1), topdict.get(each2))[0][1]\n",
    "        corrlis.append(corr_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625\n",
      "[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]\n"
     ]
    }
   ],
   "source": [
    "print(len(corrlis))\n",
    "print(corrlis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "## for weekly data\n",
    "dic = {}\n",
    "for files in glob.glob(r'E:\\\\DADV\\\\Exam\\\\500_week\\\\*.csv'):\n",
    "    f = open(files, 'r')\n",
    "    name = os.path.basename(f.name).replace(\".csv\",\"\")\n",
    "    data = pd.read_csv(f)\n",
    "    close = data[\"gainORloss\"]\n",
    "    val = close[len(close) - 1] - close[1]\n",
    "    dic[name] = val\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AGN': 1.5267600203923166,\n",
       " 'ABT': 1.3678941438463994,\n",
       " 'ACN': 1.0725321637511058,\n",
       " 'ALL': 1.0482130587643894}"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sortdic = {k: v for k, v in sorted(dic.items(), key=lambda item: item[1], reverse = True)}\n",
    "k = 1\n",
    "topdic = {}\n",
    "for each in sortdic.keys():\n",
    "    topdic[each] = sortdic.get(each)\n",
    "    k = k+1\n",
    "    if(k == 5):\n",
    "        break\n",
    "topdic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AIG': -3.3300032745587202,\n",
       " 'AMD': -3.106768880502756,\n",
       " 'AAPL': -2.6564820213864095,\n",
       " 'ABBV': -1.9442356378139891}"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sortdicrev = {k: v for k, v in sorted(dic.items(), key=lambda item: item[1])}\n",
    "k = 1\n",
    "bottomdic = {}\n",
    "for each in sortdicrev.keys():\n",
    "    bottomdic[each] = sortdicrev.get(each)\n",
    "    k = k+1\n",
    "    if(k == 5):\n",
    "        break\n",
    "bottomdic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrlist = []\n",
    "for i in topdic.keys():\n",
    "    for j in topdic.keys():\n",
    "        corrValue = np.corrcoef(topdic.get(i), topdic.get(j))[0][1]\n",
    "        corrlist.append(corrValue)\n",
    "len(corrlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "## for monthly data\n",
    "dic = {}\n",
    "for files in glob.glob(r'E:\\\\DADV\\\\Exam\\\\500_month\\\\*.csv'):\n",
    "    f = open(files, 'r')\n",
    "    name = os.path.basename(f.name).replace(\".csv\",\"\")\n",
    "    data = pd.read_csv(f)\n",
    "    close = data[\"gainORloss\"]\n",
    "    val = close[len(close) - 1] - close[1]\n",
    "    dic[name] = val\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AMZN': 19.396373335714173,\n",
       " 'BA': 16.77907041762944,\n",
       " 'BIIB': 8.406886279329996,\n",
       " 'BAC': 7.75}"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sortdic = {k: v for k, v in sorted(dic.items(), key=lambda item: item[1], reverse = True)}\n",
    "k = 1\n",
    "topdic = {}\n",
    "for each in sortdic.keys():\n",
    "    topdic[each] = sortdic.get(each)\n",
    "    k = k+1\n",
    "    if(k == 5):\n",
    "        break\n",
    "topdic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ABBV': -3.2132839443469834,\n",
       " 'ADBE': -2.567942204174358,\n",
       " 'ACN': -2.3273752653517477,\n",
       " 'AGN': -1.6564363860790365}"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sortdicrev = {k: v for k, v in sorted(dic.items(), key=lambda item: item[1])}\n",
    "k = 1\n",
    "bottomdic = {}\n",
    "for each in sortdicrev.keys():\n",
    "    bottomdic[each] = sortdicrev.get(each)\n",
    "    k = k+1\n",
    "    if(k == 5):\n",
    "        break\n",
    "bottomdic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrlist = []\n",
    "for i in topdic.keys():\n",
    "    for j in topdic.keys():\n",
    "        corrValue = np.corrcoef(topdic.get(i), topdic.get(j))[0][1]\n",
    "        corrlist.append(corrValue)\n",
    "len(corrlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For Top25 correlation plot\n",
    "corrdic = {}\n",
    "for files in glob.glob('E:\\\\DADV\\\\Exam\\\\500_day\\\\*.csv'):\n",
    "    f=open(files, 'r')\n",
    "    name = os.path.basename(f.name).replace(\".csv\",\"\")\n",
    "    if name in topdict.keys():\n",
    "        data = pd.read_csv(f)\n",
    "        close = list(data[\"gainORloss\"])\n",
    "        corrdic[name] = close\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['AAP', 'ADM', 'AEE', 'AEP', 'AFL', 'AGN', 'AIG', 'AIV', 'AJG', 'ALGN', 'ALK', 'ALL', 'AMD', 'AME', 'ANTM', 'AON', 'ARE', 'ATO', 'AWK', 'AXP', 'GOOG', 'GOOGL', 'LNT', 'MCD', 'MMM'])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrdic.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making all equal sized lists (for correlation to happen)\n",
    "max_length = 0\n",
    "for lis in corrdic.values():\n",
    "    max_length = max(max_length, len(lis))\n",
    "\n",
    "for lis in corrdic.values():\n",
    "    lis += [0.0] * (max_length - len(lis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from scipy import interpolate\n",
    "corrlis = []\n",
    "for each1 in corrdic.keys():\n",
    "    for each2 in corrdic.keys():\n",
    "        corr_value = np.corrcoef(corrdic.get(each1), corrdic.get(each2)) [0][1]\n",
    "        if np.isnan(corr_value):\n",
    "            corrlis.append(0)\n",
    "        else:\n",
    "            corrlis.append(corr_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "625"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corrlis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('correlationDataForTop25.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"CompanyA\",\"CompanyB\",\"Value\"])\n",
    "    i = 1\n",
    "    for each1 in corrdic.keys():\n",
    "        j = 1\n",
    "        for each2 in corrdic.keys():\n",
    "            corr_value = np.corrcoef(corrdic.get(each1), corrdic.get(each2)) [0][1]\n",
    "            if np.isnan(corr_value):\n",
    "                writer.writerow([each1, each2, 0])\n",
    "            else:\n",
    "                writer.writerow([each1, each2, corr_value])\n",
    "            j = j + 1\n",
    "        i = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For Bottom25 correlation plot\n",
    "corrdic = {}\n",
    "for files in glob.glob('E:\\\\DADV\\\\Exam\\\\500_day\\\\*.csv'):\n",
    "    f=open(files, 'r')\n",
    "    name = os.path.basename(f.name).replace(\".csv\",\"\")\n",
    "    if name in bottomdict.keys():\n",
    "        data = pd.read_csv(f)\n",
    "        close = list(data[\"gainORloss\"])\n",
    "        corrdic[name] = close\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['AAL', 'AAPL', 'ABBV', 'ABC', 'ABMD', 'ABT', 'ADBE', 'AES', 'AIZ', 'AKAM', 'ALB', 'ALLE', 'ALXN', 'AMAT', 'AMP', 'AMT', 'AMZN', 'ANSS', 'AOS', 'APA', 'APD', 'APH', 'APTV', 'ARNC', 'ATVI'])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrdic.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making all equal sized lists (for correlation to happen)\n",
    "max_length = 0\n",
    "for lis in corrdic.values():\n",
    "    max_length = max(max_length, len(lis))\n",
    "\n",
    "for lis in corrdic.values():\n",
    "    lis += [0.0] * (max_length - len(lis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from scipy import interpolate\n",
    "corrlis = []\n",
    "for each1 in corrdic.keys():\n",
    "    for each2 in corrdic.keys():\n",
    "        corr_value = np.corrcoef(corrdic.get(each1), corrdic.get(each2)) [0][1]\n",
    "        if np.isnan(corr_value):\n",
    "            corrlis.append(0)\n",
    "        else:\n",
    "            corrlis.append(corr_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "625"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corrlis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('correlationDataForBottom25.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"CompanyA\",\"CompanyB\",\"Value\"])\n",
    "    i = 1\n",
    "    for each1 in corrdic.keys():\n",
    "        j = 1\n",
    "        for each2 in corrdic.keys():\n",
    "            corr_value = np.corrcoef(corrdic.get(each1), corrdic.get(each2)) [0][1]\n",
    "            if np.isnan(corr_value):\n",
    "                writer.writerow([each1, each2, 0])\n",
    "            else:\n",
    "                writer.writerow([each1, each2, corr_value])\n",
    "            j = j + 1\n",
    "        i = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Security</th>\n",
       "      <th>SEC filings</th>\n",
       "      <th>GICS Sector</th>\n",
       "      <th>GICS Sub Industry</th>\n",
       "      <th>Headquarters Location</th>\n",
       "      <th>Date first added</th>\n",
       "      <th>CIK</th>\n",
       "      <th>Founded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MMM</td>\n",
       "      <td>3M Company</td>\n",
       "      <td>reports</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>Industrial Conglomerates</td>\n",
       "      <td>St. Paul Minnesota</td>\n",
       "      <td></td>\n",
       "      <td>66740</td>\n",
       "      <td>1902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABT</td>\n",
       "      <td>Abbott Laboratories</td>\n",
       "      <td>reports</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>Health Care Equipment</td>\n",
       "      <td>North Chicago Illinois</td>\n",
       "      <td>1964-03-31</td>\n",
       "      <td>1800</td>\n",
       "      <td>1888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABBV</td>\n",
       "      <td>AbbVie Inc.</td>\n",
       "      <td>reports</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>Pharmaceuticals</td>\n",
       "      <td>North Chicago Illinois</td>\n",
       "      <td>2012-12-31</td>\n",
       "      <td>1551152</td>\n",
       "      <td>2013 (1888)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABMD</td>\n",
       "      <td>ABIOMED Inc</td>\n",
       "      <td>reports</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>Health Care Equipment</td>\n",
       "      <td>Danvers Massachusetts</td>\n",
       "      <td>2018-05-31</td>\n",
       "      <td>815094</td>\n",
       "      <td>1981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACN</td>\n",
       "      <td>Accenture plc</td>\n",
       "      <td>reports</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>IT Consulting &amp; Other Services</td>\n",
       "      <td>Dublin Ireland</td>\n",
       "      <td>2011-07-06</td>\n",
       "      <td>1467373</td>\n",
       "      <td>1989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>YUM</td>\n",
       "      <td>Yum! Brands Inc</td>\n",
       "      <td>reports</td>\n",
       "      <td>Consumer Discretionary</td>\n",
       "      <td>Restaurants</td>\n",
       "      <td>Louisville Kentucky</td>\n",
       "      <td>1997-10-06</td>\n",
       "      <td>1041061</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>ZBRA</td>\n",
       "      <td>Zebra Technologies</td>\n",
       "      <td>reports</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>Electronic Equipment &amp; Instruments</td>\n",
       "      <td>Lincolnshire Illinois</td>\n",
       "      <td>2019-12-23</td>\n",
       "      <td>877212</td>\n",
       "      <td>1969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>ZBH</td>\n",
       "      <td>Zimmer Biomet Holdings</td>\n",
       "      <td>reports</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>Health Care Equipment</td>\n",
       "      <td>Warsaw Indiana</td>\n",
       "      <td>2001-08-07</td>\n",
       "      <td>1136869</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>ZION</td>\n",
       "      <td>Zions Bancorp</td>\n",
       "      <td>reports</td>\n",
       "      <td>Financials</td>\n",
       "      <td>Regional Banks</td>\n",
       "      <td>Salt Lake City Utah</td>\n",
       "      <td>2001-06-22</td>\n",
       "      <td>109380</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>ZTS</td>\n",
       "      <td>Zoetis</td>\n",
       "      <td>reports</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>Pharmaceuticals</td>\n",
       "      <td>Florham Park New Jersey</td>\n",
       "      <td>2013-06-21</td>\n",
       "      <td>1555280</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>505 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Symbol                 Security  SEC filings              GICS Sector  \\\n",
       "0      MMM               3M Company      reports              Industrials   \n",
       "1      ABT      Abbott Laboratories      reports              Health Care   \n",
       "2     ABBV              AbbVie Inc.      reports              Health Care   \n",
       "3     ABMD              ABIOMED Inc      reports              Health Care   \n",
       "4      ACN            Accenture plc      reports   Information Technology   \n",
       "..     ...                      ...          ...                      ...   \n",
       "500    YUM          Yum! Brands Inc      reports   Consumer Discretionary   \n",
       "501   ZBRA       Zebra Technologies      reports   Information Technology   \n",
       "502    ZBH   Zimmer Biomet Holdings      reports              Health Care   \n",
       "503   ZION            Zions Bancorp      reports               Financials   \n",
       "504    ZTS                   Zoetis      reports              Health Care   \n",
       "\n",
       "                       GICS Sub Industry     Headquarters Location  \\\n",
       "0               Industrial Conglomerates        St. Paul Minnesota   \n",
       "1                  Health Care Equipment    North Chicago Illinois   \n",
       "2                        Pharmaceuticals    North Chicago Illinois   \n",
       "3                  Health Care Equipment     Danvers Massachusetts   \n",
       "4         IT Consulting & Other Services            Dublin Ireland   \n",
       "..                                   ...                       ...   \n",
       "500                          Restaurants       Louisville Kentucky   \n",
       "501   Electronic Equipment & Instruments     Lincolnshire Illinois   \n",
       "502                Health Care Equipment            Warsaw Indiana   \n",
       "503                       Regional Banks       Salt Lake City Utah   \n",
       "504                      Pharmaceuticals   Florham Park New Jersey   \n",
       "\n",
       "     Date first added      CIK       Founded  \n",
       "0                        66740          1902  \n",
       "1          1964-03-31     1800          1888  \n",
       "2          2012-12-31  1551152   2013 (1888)  \n",
       "3          2018-05-31   815094          1981  \n",
       "4          2011-07-06  1467373          1989  \n",
       "..                ...      ...           ...  \n",
       "500        1997-10-06  1041061                \n",
       "501        2019-12-23   877212          1969  \n",
       "502        2001-08-07  1136869                \n",
       "503        2001-06-22   109380                \n",
       "504        2013-06-21  1555280                \n",
       "\n",
       "[505 rows x 9 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp500 = pd.read_csv(\"SP500.csv\", sep = ',')\n",
    "sp500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp500.set_index('Symbol', inplace = True)\n",
    "# for each in topdict.keys():\n",
    "#     sp500.loc[each, 'GICS Sector']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "for each in topdict.keys():\n",
    "    topdict[each] = sp500.loc[each].iloc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'GOOG': ' Interactive Media & Services',\n",
       " 'GOOGL': ' Interactive Media & Services',\n",
       " 'AIG': ' Property & Casualty Insurance',\n",
       " 'AEP': ' Electric Utilities',\n",
       " 'AWK': ' Water Utilities',\n",
       " 'LNT': ' Electric Utilities',\n",
       " 'ATO': ' Gas Utilities',\n",
       " 'AAP': ' Automotive Retail',\n",
       " 'AEE': ' Multi-Utilities',\n",
       " 'MCD': ' Restaurants',\n",
       " 'AGN': ' Pharmaceuticals',\n",
       " 'MMM': ' Industrial Conglomerates',\n",
       " 'AMD': ' Semiconductors',\n",
       " 'AON': ' Insurance Brokers',\n",
       " 'AFL': ' Life & Health Insurance',\n",
       " 'ALGN': ' Health Care Supplies',\n",
       " 'AJG': ' Insurance Brokers',\n",
       " 'ANTM': ' Managed Health Care',\n",
       " 'ALK': ' Airlines',\n",
       " 'AIV': ' Residential REITs',\n",
       " 'ALL': ' Property & Casualty Insurance',\n",
       " 'ARE': ' Office REITs',\n",
       " 'ADM': ' Agricultural Products',\n",
       " 'AME': ' Electrical Components & Equipment'}"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "for each2 in bottomdict.keys():\n",
    "    bottomdict[each2] = sp500.loc[each2].iloc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ALB': ' Specialty Chemicals',\n",
       " 'AAL': ' Airlines',\n",
       " 'APTV': ' Auto Parts & Equipment',\n",
       " 'AMP': ' Asset Management & Custody Banks',\n",
       " 'APH': ' Electronic Components',\n",
       " 'AMAT': ' Semiconductor Equipment',\n",
       " 'ALXN': ' Biotechnology',\n",
       " 'ABBV': ' Pharmaceuticals',\n",
       " 'ABMD': ' Health Care Equipment',\n",
       " 'ANSS': ' Application Software',\n",
       " 'ABT': ' Health Care Equipment',\n",
       " 'AAPL': ' Technology Hardware Storage & Peripherals',\n",
       " 'APD': ' Industrial Gases',\n",
       " 'AMZN': ' Internet & Direct Marketing Retail',\n",
       " 'APA': ' Oil & Gas Exploration & Production',\n",
       " 'AES': ' Independent Power Producers & Energy Traders',\n",
       " 'ADBE': ' Application Software',\n",
       " 'AIZ': ' Multi-line Insurance',\n",
       " 'ATVI': ' Interactive Home Entertainment',\n",
       " 'AMT': ' Specialized REITs',\n",
       " 'ABC': ' Health Care Distributors',\n",
       " 'ALLE': ' Building Products',\n",
       " 'AOS': ' Building Products',\n",
       " 'ARNC': ' Aerospace & Defense'}"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bottomdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "topCount = {}\n",
    "for each in topdict.keys():\n",
    "    sector = topdict.get(each)\n",
    "    if sector in topCount.keys():\n",
    "        topCount[sector] += 1\n",
    "    else:\n",
    "        topCount[sector] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' Interactive Media & Services': 2,\n",
       " ' Property & Casualty Insurance': 2,\n",
       " ' Electric Utilities': 2,\n",
       " ' Water Utilities': 1,\n",
       " ' Gas Utilities': 1,\n",
       " ' Automotive Retail': 1,\n",
       " ' Multi-Utilities': 1,\n",
       " ' Restaurants': 1,\n",
       " ' Pharmaceuticals': 1,\n",
       " ' Industrial Conglomerates': 1,\n",
       " ' Semiconductors': 1,\n",
       " ' Insurance Brokers': 2,\n",
       " ' Life & Health Insurance': 1,\n",
       " ' Health Care Supplies': 1,\n",
       " ' Managed Health Care': 1,\n",
       " ' Airlines': 1,\n",
       " ' Residential REITs': 1,\n",
       " ' Office REITs': 1,\n",
       " ' Agricultural Products': 1,\n",
       " ' Electrical Components & Equipment': 1}"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "bottomCount = {}\n",
    "for each in bottomdict.keys():\n",
    "    sector = bottomdict.get(each)\n",
    "    if sector in bottomCount.keys():\n",
    "        bottomCount[sector] += 1\n",
    "    else:\n",
    "        bottomCount[sector] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' Specialty Chemicals': 1,\n",
       " ' Airlines': 1,\n",
       " ' Auto Parts & Equipment': 1,\n",
       " ' Asset Management & Custody Banks': 1,\n",
       " ' Electronic Components': 1,\n",
       " ' Semiconductor Equipment': 1,\n",
       " ' Biotechnology': 1,\n",
       " ' Pharmaceuticals': 1,\n",
       " ' Health Care Equipment': 2,\n",
       " ' Application Software': 2,\n",
       " ' Technology Hardware Storage & Peripherals': 1,\n",
       " ' Industrial Gases': 1,\n",
       " ' Internet & Direct Marketing Retail': 1,\n",
       " ' Oil & Gas Exploration & Production': 1,\n",
       " ' Independent Power Producers & Energy Traders': 1,\n",
       " ' Multi-line Insurance': 1,\n",
       " ' Interactive Home Entertainment': 1,\n",
       " ' Specialized REITs': 1,\n",
       " ' Health Care Distributors': 1,\n",
       " ' Building Products': 2,\n",
       " ' Aerospace & Defense': 1}"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bottomCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{' Interactive Media & Services': 2, ' Property & Casualty Insurance': 2, ' Electric Utilities': 2, ' Water Utilities': 1, ' Gas Utilities': 1, ' Automotive Retail': 1, ' Multi-Utilities': 1, ' Restaurants': 1, ' Pharmaceuticals': 1, ' Industrial Conglomerates': 1, ' Semiconductors': 1, ' Insurance Brokers': 2, ' Life & Health Insurance': 1, ' Health Care Supplies': 1, ' Managed Health Care': 1, ' Airlines': 1, ' Residential REITs': 1, ' Office REITs': 1, ' Agricultural Products': 1, ' Electrical Components & Equipment': 1, ' Specialty Chemicals': 1, ' Auto Parts & Equipment': 1, ' Asset Management & Custody Banks': 1, ' Electronic Components': 1, ' Semiconductor Equipment': 1, ' Biotechnology': 1, ' Health Care Equipment': 2, ' Application Software': 2, ' Technology Hardware Storage & Peripherals': 1, ' Industrial Gases': 1, ' Internet & Direct Marketing Retail': 1, ' Oil & Gas Exploration & Production': 1, ' Independent Power Producers & Energy Traders': 1, ' Multi-line Insurance': 1, ' Interactive Home Entertainment': 1, ' Specialized REITs': 1, ' Health Care Distributors': 1, ' Building Products': 2, ' Aerospace & Defense': 1}\n"
     ]
    }
   ],
   "source": [
    "def Merge(dict1, dict2): \n",
    "    res = {**dict1, **dict2} \n",
    "    return res\n",
    "\n",
    "merged = Merge(topCount, bottomCount)\n",
    "print(merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "finaldict = {}        \n",
    "for each in bottomCount.keys():\n",
    "    if each in finaldict.keys():\n",
    "        finaldict[each] = finaldict.get(each).append(bottomCount.get(each))\n",
    "    else:\n",
    "        lis = [bottomCount.get(each)]\n",
    "        finaldict[each] = lis\n",
    "        \n",
    "for each in topCount.keys():\n",
    "    if each in finaldict.keys():\n",
    "        finaldict[each] = finaldict.get(each).append(topCount.get(each))\n",
    "    else:\n",
    "        lis = [topCount.get(each)]\n",
    "        finaldict[each] = lis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' Specialty Chemicals': [1],\n",
       " ' Airlines': None,\n",
       " ' Auto Parts & Equipment': [1],\n",
       " ' Asset Management & Custody Banks': [1],\n",
       " ' Electronic Components': [1],\n",
       " ' Semiconductor Equipment': [1],\n",
       " ' Biotechnology': [1],\n",
       " ' Pharmaceuticals': None,\n",
       " ' Health Care Equipment': [2],\n",
       " ' Application Software': [2],\n",
       " ' Technology Hardware Storage & Peripherals': [1],\n",
       " ' Industrial Gases': [1],\n",
       " ' Internet & Direct Marketing Retail': [1],\n",
       " ' Oil & Gas Exploration & Production': [1],\n",
       " ' Independent Power Producers & Energy Traders': [1],\n",
       " ' Multi-line Insurance': [1],\n",
       " ' Interactive Home Entertainment': [1],\n",
       " ' Specialized REITs': [1],\n",
       " ' Health Care Distributors': [1],\n",
       " ' Building Products': [2],\n",
       " ' Aerospace & Defense': [1],\n",
       " ' Interactive Media & Services': [2],\n",
       " ' Property & Casualty Insurance': [2],\n",
       " ' Electric Utilities': [2],\n",
       " ' Water Utilities': [1],\n",
       " ' Gas Utilities': [1],\n",
       " ' Automotive Retail': [1],\n",
       " ' Multi-Utilities': [1],\n",
       " ' Restaurants': [1],\n",
       " ' Industrial Conglomerates': [1],\n",
       " ' Semiconductors': [1],\n",
       " ' Insurance Brokers': [2],\n",
       " ' Life & Health Insurance': [1],\n",
       " ' Health Care Supplies': [1],\n",
       " ' Managed Health Care': [1],\n",
       " ' Residential REITs': [1],\n",
       " ' Office REITs': [1],\n",
       " ' Agricultural Products': [1],\n",
       " ' Electrical Components & Equipment': [1]}"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finaldict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('bar_data.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Company\",\"Value\"])\n",
    "    i = 1\n",
    "    for each in finaldict.keys():\n",
    "        writer.writerow([each, merged.get(each)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
